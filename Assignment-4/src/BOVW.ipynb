{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BOVW_FINAL-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov4s5hH0YncO",
        "outputId": "849c1b28-e118-46fb-fff4-f1b791c88c49"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usPA-ztNZEXz"
      },
      "source": [
        "#### Importing required libreries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_500dtoBZKXp"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import random\n",
        "from matplotlib import image \n",
        "import matplotlib.cm as cm\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQpkSh9QZOcb"
      },
      "source": [
        "#### We install a different version of OpenCV. This is because SIFT feature descriptor is not available is latest version due to patent issues."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuN4_mQkZblb",
        "outputId": "7666b8b1-38d9-4b6d-a93e-7ba6378413e6"
      },
      "source": [
        "!pip install opencv-python==3.4.2.17 opencv-contrib-python==3.4.2.17\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python==3.4.2.17 in /usr/local/lib/python3.7/dist-packages (3.4.2.17)\n",
            "Requirement already satisfied: opencv-contrib-python==3.4.2.17 in /usr/local/lib/python3.7/dist-packages (3.4.2.17)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==3.4.2.17) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REwN1Q65ZkUY"
      },
      "source": [
        "#### Below are the classes we have for classification. We have assigned a unique interger to each class as a part of preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxmFJvGMZkfE"
      },
      "source": [
        "classes = ['aquarium', 'desert', 'park', 'windmill', 'waterfall', 'highway', 'kitchen', 'laundromat']\n",
        "LABELS = {'aquarium'  :1,\n",
        "          'desert'    :2,\n",
        "          'park'      :3,\n",
        "          'windmill'  :4,\n",
        "          'waterfall' :5,\n",
        "          'highway'   :6,\n",
        "          'kitchen'   :7,\n",
        "          'laundromat':8}"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNYVFYy8aR_2"
      },
      "source": [
        "#### These are the target class labels for training and testing. We have 80 samples of each class in training data and 20 samples of each class in test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7ju57Z8aTed"
      },
      "source": [
        "y_train = np.array([[1]*80+[2]*80+[3]*80+[4]*80+[5]*80+[6]*80+[7]*80+[8]*80]).flatten()\n",
        "y_test  = np.array([[1]*20+[2]*20+[3]*20+[4]*20+[5]*20+[6]*20+[7]*20+[8]*20]).flatten()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYl-aup-amAR"
      },
      "source": [
        "#### Function of compute SIFT features for a given input image\n",
        "#### BONUS - DENSE SIFT ALSO DONE\n",
        "Window size for Dense SIFT is 20x20 and a stride of 5 is taken."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nqYsFNCamIp"
      },
      "source": [
        "def get_features(image):\n",
        "  sift = cv2.xfeatures2d.SIFT_create()\n",
        "  kp, des = sift.detectAndCompute(image, None)\n",
        "  return des\n",
        "\n",
        "def get_dense_sift_features(image):\n",
        "  n ,m, _ = image.shape\n",
        "  window_size = 20\n",
        "  stride = 5\n",
        "  features = np.zeros((1,128))\n",
        "  #print(features.shape)\n",
        "  sift = cv2.xfeatures2d.SIFT_create()\n",
        "  for x in range(0, n-window_size, stride):\n",
        "    for y in range(0, m-window_size, stride):\n",
        "      kp, des = sift.detectAndCompute(image[ x : x + window_size, y : y + window_size ], None)\n",
        "      if des is None:\n",
        "        continue\n",
        "      features = np.append(features, des, axis=0)\n",
        "  return features[1:,:]\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxsLhcc3azdK"
      },
      "source": [
        "### Preprocessing\n",
        "#### In below function, we prepare the training and testing data one by one. Following the steps involved : \n",
        "- INITIALIZE DATASET AS EMPTY\n",
        "  - We read each image of each class sequentially\n",
        "  - Resize image to 150 x 150\n",
        "  - Calculate SIFT descriptors of reduced image\n",
        "  - Append calculated descriptors of the image to dataset. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AK-Ko9_aznO"
      },
      "source": [
        "def load_data_and_preprocess(PATH, feature_type=\"sift\"):\n",
        "  data = np.zeros(128)\n",
        "  labels = np.zeros(1)\n",
        "  features = []\n",
        "  for class_ in classes:\n",
        "    img_path = PATH + class_ \n",
        "    print(class_, LABELS[class_])\n",
        "    for filename in os.listdir(img_path):\n",
        "      img = cv2.imread(os.path.join(img_path,filename))\n",
        "      img = cv2.resize(img, (150, 150))\n",
        "      if (feature_type==\"dense-sift\"):\n",
        "        desc = get_dense_sift_features(img)\n",
        "      else:\n",
        "        desc = get_features(img)\n",
        "      label = np.zeros(desc.shape[0]) + LABELS[class_]\n",
        "      labels = np.append(labels, label)\n",
        "      features.append(desc)\n",
        "      data = np.vstack((data,desc)) \n",
        "  data = data[1:]\n",
        "  labels = labels[1:]\n",
        "  return data, features, labels"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwlbVBYicWmp"
      },
      "source": [
        "#### Preparing training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Pj8KMsrcZEa",
        "outputId": "a5931b20-51e4-4a4d-ec42-1d2a4438db05"
      },
      "source": [
        "train_path = '/content/drive/My Drive/COMPUTER VISION/SUN_data/SUN_data/train/'\n",
        "data, features, labels = load_data_and_preprocess(train_path, feature_type=\"dense-sift\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aquarium 1\n",
            "desert 2\n",
            "park 3\n",
            "windmill 4\n",
            "waterfall 5\n",
            "highway 6\n",
            "kitchen 7\n",
            "laundromat 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkDSKqM2cZm5"
      },
      "source": [
        "#### Preparing testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2MszDywcbb8",
        "outputId": "b5701da3-4187-4adb-8fc3-106ee61a11f4"
      },
      "source": [
        "test_path = '/content/drive/My Drive/COMPUTER VISION/SUN_data/SUN_data/test/'\n",
        "data_test, features_test, labels_test = load_data_and_preprocess(test_path, feature_type=\"dense-sift\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aquarium 1\n",
            "desert 2\n",
            "park 3\n",
            "windmill 4\n",
            "waterfall 5\n",
            "highway 6\n",
            "kitchen 7\n",
            "laundromat 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N9zh7Mvcyjo"
      },
      "source": [
        "### Kmeans CLustering\n",
        "#### Here, we take the input dataset (set of all SIFT feature descriptors of all images) and perform kmeans clustering on them. This is done to get descriptor of same things together in a same cluster as a part of bag of visual words technique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKYrDldtczDR"
      },
      "source": [
        "def clustering(Xtrain, num_clusters):\n",
        "    kmeans = KMeans(n_clusters = num_clusters)\n",
        "    kmeans.fit(Xtrain)\n",
        "    return kmeans"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLK4GL9hda_D"
      },
      "source": [
        "### BOVW for Retrieval : Inverted File Indexing\n",
        "#### In this function, we create the index table. Following are the steps involved : \n",
        "- INITIALIZE : Zero matrix of size ( No. of cluster X No. of Images)\n",
        " \n",
        "We'll call this matrix as ***INDEX TABLE*** from now onwards\n",
        " - Go through each feature descriptor in dataset\n",
        "  - Predict its cluster accoring to the clustering done in previous step using kmeans\n",
        "  - Increament the corressponding entry in index table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTGBzfaydbH4"
      },
      "source": [
        "def inverted_file_indexing( features, Kmeans, num_clusters):\n",
        "  num_images = len(features)\n",
        "  index_table = np.zeros((num_clusters, num_images))\n",
        "  print(num_images,index_table.shape)\n",
        "  for i in range(num_images):\n",
        "    for feature in features[i]:\n",
        "      Feature = feature.reshape(1, 128)\n",
        "      cluster_idx = Kmeans.predict(Feature)[0]\n",
        "      index_table[cluster_idx][i] += 1\n",
        "  return index_table"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6px_lK5iSit"
      },
      "source": [
        "#### Histogram PLotting\n",
        "##### Below function is used to plot the histogram of cluster obtained after applying clustering on the feature descriptors of all images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z-4bjI1ihjt"
      },
      "source": [
        "def display_orig_BOVW_histogram(index_table  ,num_clusters ):\n",
        "  x_scalar = np.arange(num_clusters)\n",
        "  y_scalar = np.sum(index_table, axis=1)\n",
        "  plt.figure(figsize=(15,8))\n",
        "  plt.bar(x_scalar, y_scalar)\n",
        "  plt.xlabel(\"Visual Word Index\")\n",
        "  plt.ylabel(\"Frequency\")\n",
        "  plt.title(\"Complete Vocabulary Generated\")\n",
        "  #plt.xticks(x_scalar + 0.4, x_scalar)\n",
        "  plt.show()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJHnP7vUjeQJ"
      },
      "source": [
        "### Normalization\n",
        "#### In this section, we have normalized the Index Table. This is done by subtracting the mean and dividing by standard deviation\n",
        "\n",
        "Normalized data = ( Data - Mean ) / Standard_deviation\n",
        "\n",
        "After normalization, we have performed classification using the normalized index table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiDeSAi9jgpC"
      },
      "source": [
        "def normalize(index_table, index_table_test):\n",
        "  normalized_index_table = np.copy(index_table)\n",
        "  Mean = np.mean(normalized_index_table, axis=0)\n",
        "  std_dev = np.std(normalized_index_table, axis=0)\n",
        "  normalized_index_table = (normalized_index_table - Mean)/std_dev\n",
        "\n",
        "  normalized_index_table_test = np.copy(index_table_test)\n",
        "  Mean = np.mean(normalized_index_table_test, axis=0)\n",
        "  std_dev = np.std(normalized_index_table_test, axis=0)\n",
        "  normalized_index_table_test = (normalized_index_table_test - Mean)/std_dev\n",
        "  return normalized_index_table, normalized_index_table_test\n",
        "\n",
        "def fit_normalized(index_table, index_table_test):\n",
        "  normalized_index_table, normalized_index_table_test = normalize()\n",
        "  norm_clf = applySVM(normalized_index_table.T, y_train)\n",
        "  y_pred = norm_clf.predict(normalized_index_table_test.T)\n",
        "  print(accuracy_score(y_test, y_pred))\n",
        "  print(confusion_matrix(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SGGzOyAl12J"
      },
      "source": [
        "### Evaluation\n",
        "#### - Here we have done the following : \n",
        "- Predictions for the testing\n",
        "- Calculation of accuracy\n",
        "- Computing Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "habUGGgRl3q3"
      },
      "source": [
        "def prediction(classifier, index_table_test, y_test):\n",
        "    y_pred = classifier.predict(index_table_test.T)\n",
        "    print(\"y_pred\",y_pred.shape)\n",
        "    acc = accuracy(y_pred, y_test)\n",
        "    conf_mat = print_confusion_matrix(y_pred, y_test)\n",
        "    return acc, conf_mat\n",
        "\n",
        "def accuracy(y_pred, y_test):\n",
        "    #print(accuracy_score(y_test, y_pred))\n",
        "    return accuracy_score(y_test, y_pred)\n",
        "\n",
        "def print_confusion_matrix(y_pred, y_test):\n",
        "    #print(confusion_matrix(y_test, y_pred))\n",
        "    return confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpPObnPYmulT"
      },
      "source": [
        "### Classification\n",
        "#### Support vector machine is used for classifying. We have used applyied various hyparameters like kernel, C, gamma etc. \n",
        "Since we have 8 classes in this problem so we are using 1 vs all classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J7kWYnam_29"
      },
      "source": [
        "def applySVM(trainX, trainY, c=10, Kernel=\"linear\", Gamma=5):\n",
        "    #clf = OneVsRestClassifier(SVC( C = c, gamma = Gamma, kernel = Kernel ) )\n",
        "    clf = OneVsRestClassifier(SVC() )\n",
        "    print(\"....\",trainX.shape, trainY.shape)\n",
        "    clf.fit(trainX, trainY)\n",
        "    return clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxApuIiuo3Rn"
      },
      "source": [
        "Xtrain, Xtest = data, data_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiH9wIY_o6gQ",
        "outputId": "118e5bf6-4985-4b97-fd60-f3fe59c91532"
      },
      "source": [
        "print(data.shape)\n",
        "print(labels.shape)\n",
        "print(data_test.shape)\n",
        "print(labels_test.shape)\n",
        "print(len(features), len(features_test))\n",
        "print(Xtrain.shape, y_train.shape, Xtest.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(96122, 128)\n",
            "(96122,)\n",
            "(24674, 128)\n",
            "(24674,)\n",
            "640 160\n",
            "(96122, 128) (640,) (24674, 128) (160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLjPoXd8oYih"
      },
      "source": [
        "#### Here we have done the following :\n",
        "- Clustering on ***training*** dataset\n",
        "- Creating Inverted Index table for ***training*** dataset\n",
        "- Clustering on ***testing*** dataset\n",
        "- Creating Inverted Index table for ***testing*** dataset\n",
        "- Training 1 vs all SVM classifier on training inverted index table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdpAB92QoYt0",
        "outputId": "bc4a4ae0-b67a-42b5-a53a-42f3275063a0"
      },
      "source": [
        "num_clusters = 100\n",
        "kmeans = clustering(Xtrain, num_clusters)  # Xtrain, num_clusters\n",
        "index_table = inverted_file_indexing(features, kmeans, num_clusters) #features, Kmeans, num_clusters\n",
        "print(index_table.shape, index_table)\n",
        "kmeans_test = clustering(Xtest, num_clusters) # Xtrain, num_clusters\n",
        "index_table_test = inverted_file_indexing(features_test, kmeans_test, num_clusters) #features, Kmeans, num_clusters\n",
        "print(index_table_test.shape, index_table_test)\n",
        "clf = applySVM(index_table.T, y_train, c=10, Kernel=\"rbf\", Gamma=5) # trainX, trainY, c=10, Kernel=\"linear\", Gamma=5\n",
        "acc, conf_mat = prediction(clf, index_table_test, y_test)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "640 (100, 640)\n",
            "(100, 640) [[2. 1. 0. ... 0. 5. 4.]\n",
            " [2. 3. 0. ... 0. 0. 3.]\n",
            " [0. 0. 0. ... 1. 4. 1.]\n",
            " ...\n",
            " [3. 2. 0. ... 1. 3. 0.]\n",
            " [5. 0. 0. ... 1. 2. 5.]\n",
            " [5. 1. 0. ... 1. 2. 2.]]\n",
            "160 (100, 160)\n",
            "(100, 160) [[0. 0. 0. ... 0. 1. 1.]\n",
            " [0. 1. 0. ... 3. 1. 0.]\n",
            " [1. 4. 1. ... 6. 1. 0.]\n",
            " ...\n",
            " [1. 6. 2. ... 1. 2. 0.]\n",
            " [1. 1. 0. ... 2. 0. 1.]\n",
            " [1. 0. 0. ... 0. 1. 0.]]\n",
            ".... (640, 100) (640,)\n",
            "y_pred (160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "xOsUsf7g1La8",
        "outputId": "b13b28b5-78ab-486b-c10b-c819b303c9b9"
      },
      "source": [
        "display_orig_BOVW_histogram(index_table  ,num_clusters )"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKv6L9zUur2p"
      },
      "source": [
        "#### Accuracy and confusion matrix for 1-vs-All SVM with RBF kernel "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGU_YZ6yWRFg",
        "outputId": "f3f99a62-24be-4210-dfea-946e35cea983"
      },
      "source": [
        "print(\"Accuracy =\",acc)\n",
        "print(\"Confusion matrix\\n\",conf_mat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 0.24375\n",
            "Confusion matrix\n",
            " [[ 5  4  4  1  1  0  1  4]\n",
            " [ 2 15  0  0  1  0  0  2]\n",
            " [ 4  0  5  0  3  2  3  3]\n",
            " [ 4  8  4  0  0  0  2  2]\n",
            " [ 1  0  4  1  5  0  2  7]\n",
            " [ 3  8  1  1  0  1  4  2]\n",
            " [ 3  2  1  0  3  1  4  6]\n",
            " [ 1  2  2  0  0  2  9  4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5_IrOvZu6wH"
      },
      "source": [
        "#### Accuracy and confusion matrix for 1-vs-All SVM with Linear kernel "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNFh7uUEtVGm",
        "outputId": "9386eddd-4889-46ae-8d8f-b87641e35d4c"
      },
      "source": [
        "clf = applySVM(index_table.T, y_train, c=10, Kernel=\"linear\", Gamma=5) # trainX, trainY, c=10, Kernel=\"linear\", Gamma=5\n",
        "print(\"after clf training\")\n",
        "prediction(clf, index_table_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".... (640, 100) (640,)\n",
            "after clf training\n",
            "y_pred (160,)\n",
            "0.13125\n",
            "[[ 1  1  2  7  3  2  3  1]\n",
            " [ 1  8  0  1  0  2  4  4]\n",
            " [ 1  1  3  3  9  1  1  1]\n",
            " [ 1  8  1  4  1  2  2  1]\n",
            " [ 2  0  1  6  2  2  5  2]\n",
            " [ 0  3  1  2  2  0 12  0]\n",
            " [ 3  0  1  8  0  2  2  4]\n",
            " [ 3  7  2  3  0  2  2  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChxCNSsaWrwk"
      },
      "source": [
        "### BONUS :  TF-IDF : Term Frequency (TF) - Inverse Document Frequency (IDF)\n",
        "Weighting on the histograms to enhance the importance of discriminative features and downweight the uninformative features that occur in a lot of images.\n",
        "\n",
        "n = Number Of Images\n",
        "\n",
        "m = No. Of Images Containing The visual word\n",
        "\n",
        "$IDF = Log(\\frac{n}{m})$\n",
        "\n",
        "***Words which are present in less number of images are more discriminative and have high IDF value which is used to weight them***\n",
        "\n",
        "x = No. of repetitions of visual word in an image\n",
        "\n",
        "y = Total No. of visual words in an image\n",
        "\n",
        "$TF = \\frac{x}{y}$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqEdB_-fWuGt"
      },
      "source": [
        "def TF_IDF(index_table, index_table_test, num_clusters):\n",
        "  tf_train = np.copy(index_table)\n",
        "  tf_test = np.copy(index_table_test)\n",
        "  idf_train = np.zeros(num_clusters) + index_table.shape[1]\n",
        "  idf_test = np.zeros(num_clusters) + index_table_test.shape[1]\n",
        "  # IDF calculation\n",
        "  for i in range(num_clusters):\n",
        "    idf_train[i] = np.log( idf_train[i] / np.sum(index_table[i,:]) )\n",
        "    idf_test[i]  = np.log( idf_test[i] / np.sum(index_table_test[i,:]) )\n",
        "  \n",
        "  tf_train_sum = np.sum(tf_train, axis=0)\n",
        "  tf_test_sum = np.sum(tf_test, axis=0)\n",
        "\n",
        "  for i in range(100):\n",
        "    tf_train[i,:] =  idf_train[i] * (tf_train[i,:]/tf_train_sum[i])\n",
        "    tf_test[i,:] =  idf_test[i] * (tf_test[i,:]/tf_test_sum[i])\n",
        "\n",
        "  return tf_train, tf_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryDlDsl-ZYz0"
      },
      "source": [
        "tf_train, tf_test = TF_IDF(index_table, index_table_test, num_clusters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtMw0wPaf1D3",
        "outputId": "395a089e-4026-490e-bac3-fc8775a64972"
      },
      "source": [
        "clf = applySVM(tf_train.T, y_train, c=10, Kernel=\"linear\", Gamma=5) # trainX, trainY, c=10, Kernel=\"linear\", Gamma=5\n",
        "print(\"after clf training\")\n",
        "acc, conf_mat = prediction(clf, tf_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".... (640, 100) (640,)\n",
            "after clf training\n",
            "y_pred (160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByWf9PTSyHW5"
      },
      "source": [
        "### Result after applying SVM on TF-IDF re-weighed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V6Yns3AgIH0",
        "outputId": "8c8d9bac-9e06-4a14-c268-83a038148ffb"
      },
      "source": [
        "print(\"Accuracy =\",acc)\n",
        "print(\"Confusion matrix\\n\",conf_mat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 0.14375\n",
            "Confusion matrix\n",
            " [[ 2 17  1  0  0  0  0  0]\n",
            " [ 0 20  0  0  0  0  0  0]\n",
            " [ 0 18  1  1  0  0  0  0]\n",
            " [ 4 16  0  0  0  0  0  0]\n",
            " [ 0 19  0  1  0  0  0  0]\n",
            " [ 1 17  2  0  0  0  0  0]\n",
            " [ 1 16  0  2  0  0  0  1]\n",
            " [ 2 16  0  2  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHImU45wgNbO"
      },
      "source": [
        "### BONUS - BOVW with spatial pyramid matching\n",
        "\n",
        "Number of pyramid levels = 3 \n",
        "\n",
        "Weights for Layer 1, 2 and 3 are 1/4, 1/4 and 1/2.\n",
        "\n",
        "Layer 1 : Entire image is taken as itself.\n",
        "\n",
        "Layer 2 : 4 equal partitions are taken of the image.\n",
        "\n",
        "Layer 3 : 16 equal partitions are taken of the image.\n",
        "\n",
        "Hence, the number of histograms that we get are 1+4+16 = 21\n",
        "\n",
        "Now, for n clusters, the total number of features that we get after concating all histograms is 21*n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSXCMRYvgPMC"
      },
      "source": [
        "def make_histogram(features, kmeans, num_clusters):\n",
        "  hist = np.zeros(num_clusters)\n",
        "  if features is None:\n",
        "    return hist\n",
        "  for feature in features:\n",
        "    pred = kmeans.predict([feature])\n",
        "    hist[pred] += 1\n",
        "  return hist\n",
        "\n",
        "def get_spatial_pyramid_histogram(image, L, kmeans, num_clusters):\n",
        "  all_histograms = []\n",
        "  weights = [0.25, 0.25, 0.5]\n",
        "  for level in range(L):\n",
        "      size = 2**level\n",
        "      stride = image.shape[0]//size\n",
        "      height, width, _ = image.shape\n",
        "      for i in range(0, height, stride):\n",
        "        for j in range(0, width, stride):\n",
        "          img_portion = image[i:i+stride, j:j+stride, :]\n",
        "          desc = get_features(img_portion)\n",
        "          hist = make_histogram(desc, kmeans, num_clusters)\n",
        "          all_histograms.append( weights[level]*hist )\n",
        "\n",
        "  cumulative_hist = all_histograms[0]\n",
        "  lenn = len(all_histograms)\n",
        "  for i in range(1, lenn):\n",
        "    cumulative_hist = np.concatenate((cumulative_hist, all_histograms[i]))\n",
        "  cumulative_hist = ( cumulative_hist - np.mean(cumulative_hist) ) / np.std(cumulative_hist)\n",
        "  return cumulative_hist\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skvWyUhum_Ig"
      },
      "source": [
        "num_clusters = 100\n",
        "\n",
        "def load_spatial_data(PATH):\n",
        "  data = np.zeros(2100)\n",
        "  for class_ in classes:\n",
        "    img_path = PATH + class_ \n",
        "    print(class_, LABELS[class_])\n",
        "    for filename in os.listdir(img_path):\n",
        "      img = cv2.imread(os.path.join(img_path,filename))\n",
        "      img = cv2.resize(img, (160, 160))\n",
        "      desc = get_spatial_pyramid_histogram(img, 3, kmeans, num_clusters)\n",
        "      data = np.vstack((data,desc)) \n",
        "  data = data[1:]\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OllUZIjc2X-s",
        "outputId": "e8ca6661-0d4a-43a4-a71a-818b69218a20"
      },
      "source": [
        "Xtrain_pyd = load_spatial_data(train_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aquarium 1\n",
            "desert 2\n",
            "park 3\n",
            "windmill 4\n",
            "waterfall 5\n",
            "highway 6\n",
            "kitchen 7\n",
            "laundromat 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l68D_TWL3zLo",
        "outputId": "f5698543-349e-434b-b0a1-7d996fcbff55"
      },
      "source": [
        "Xtest_pyd = load_spatial_data(test_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aquarium 1\n",
            "desert 2\n",
            "park 3\n",
            "windmill 4\n",
            "waterfall 5\n",
            "highway 6\n",
            "kitchen 7\n",
            "laundromat 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0r_Rm7E4Qvf",
        "outputId": "d5442d5b-b6d7-4aab-ce46-349dfae02f57"
      },
      "source": [
        "print(Xtrain_pyd.shape,Xtest_pyd.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(640, 2100) (160, 2100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OKtP_Rv4jWa",
        "outputId": "20b38488-9c2a-4830-c6a2-5d72a7873e74"
      },
      "source": [
        "clf = applySVM(Xtrain_pyd, y_train, c=10, Kernel=\"linear\", Gamma=5) # trainX, trainY, c=10, Kernel=\"linear\", Gamma=5\n",
        "print(\"after clf training\")\n",
        "acc, conf_mat = prediction(clf, Xtest_pyd.T, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".... (640, 2100) (640,)\n",
            "after clf training\n",
            "y_pred (160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzCSVuA24qbz",
        "outputId": "4b99aaec-39d2-4704-f68e-3221bfa42864"
      },
      "source": [
        "print(\"Accuracy =\",acc)\n",
        "print(\"Confusion matrix\\n\",conf_mat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 0.51875\n",
            "Confusion matrix\n",
            " [[13  0  3  3  1  0  0  0]\n",
            " [ 0 15  0  1  2  1  0  1]\n",
            " [ 2  0 12  0  2  2  0  2]\n",
            " [ 0  8  3  4  1  2  1  1]\n",
            " [ 1  0  5  1 13  0  0  0]\n",
            " [ 1  4  1  2  2  6  2  2]\n",
            " [ 2  0  2  0  2  0 11  3]\n",
            " [ 1  0  2  0  0  3  5  9]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}